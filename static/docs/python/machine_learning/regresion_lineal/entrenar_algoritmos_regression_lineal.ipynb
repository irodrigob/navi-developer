{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresor de KNN o vecinos cercanos\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Set de datos de boston\n",
    "from sklearn.datasets import load_boston\n",
    "# Divide los datos entre entrenamiento y testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Algoritmos de regresión linea y ridge\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# A la variable boston se le asigna el set de datos. Que son los precios de las casas en boston que depende de varías características\n",
    "boston = load_boston()\n",
    "\n",
    "# Visualiza las claves que tiene los datos\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(506,)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# La data son las características\n",
    "#boston.data\n",
    "\n",
    "# Respuestas a nuestras características\n",
    "#boston.target\n",
    "\n",
    "# Ver los ejemplos que hay en data. Que devuelve 506, 13. Que son 506 casa con 13 características\n",
    "#boston.data.shape\n",
    "\n",
    "# Si se hace lo mismo pero con el target devuelve 506 respuestas\n",
    "#boston.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las que terminan en \"_ent\" son para entrenar y las que terminan en \"_test\" son para testing.\n",
    "# Estas variables se inicializan con la data o características y las etiquetas\n",
    "X_ent, X_test, y_ent, y_test = train_test_split(boston.data, boston.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Datos para entrenar: (379, 13)\nDatos para testing: (127, 13)\nDatos y para entrenar: (379,)\nDatos y para testing: (127,)\n"
    }
   ],
   "source": [
    "# Si hacemos esto se que son los datos que ha usado para entrenar. Que serán 379, 13\n",
    "print(\"Datos para entrenar:\",X_ent.shape)\n",
    "# Y para testing devuelve el resto 127, 13\n",
    "print(\"Datos para testing:\",X_test.shape)\n",
    "# resto de variables que son los vector pero sin las características. Solo devuelve 379 para _ent y 127 para _test\n",
    "print(\"Datos y para entrenar:\", y_ent.shape)\n",
    "print(\"Datos y para testing:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable que se le asocia con el algoritmo de vecinos cercanos. Pasándole que considere 3 vecinos.\n",
    "knn = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsRegressor(n_neighbors=3)"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Se le pasa al algoritmo los datos de entrenamiento y los valores objetivos o guia.\n",
    "# Al ejecutar se visualizará los parámetros del algoritmo que han sido modificados, como es el número de vecinos.\n",
    "knn.fit(X_ent,y_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.48765714459865794"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Para saber como aprendio nuestro algoritmo se le pasan los datos de test. \n",
    "# Si se le pasa 3 vecinos el % de aprendizaje es un 48%.  Pero si se le sube el valor del parámetro n_neighbors a 5 el % de aprendizaje\n",
    "# disminuye al 47%. Y si ponemos 4 es un poco inferior al 3. Por ello, el más optimo es dejarlo en 3 para este set de datos.\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se borra el contenido de la variable para poder usar la libreria \"LinearRegressionLinearRegression\"\n",
    "# El objetivo de borrar es evitar que la maquia se sature al procesos varios modelos\n",
    "del knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression()"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Se alimenta con los mismos datos que para el algoritmo de vecinos cercanos\n",
    "rl.fit(X_ent,y_ent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7234736597353022"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# Vamos a ver cual ha sido su nivel de aprendizaje. Pasandole los mismos datos que para el KNN\n",
    "# Em este caso ha aprendido un 72% mucho mejor que el 48% del KNN\n",
    "rl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se va hacer lo mismo pero con el algoritmo de ridger\n",
    "del rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Ridge(alpha=1)"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# Se vuelve alimentar con los mismo datos de los algoritmos anteriores\n",
    "ridge.fit(X_ent, y_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7295909932230014"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# Y ahora a ver cuanto ha aprendido\n",
    "# Devuelve un 72%(redonde hacia arriba) que es un poco mejor al algoritmo de regression lineal\n",
    "# Cambiando el parámetro alpha a 0.5 devuelve un valor sensible inferior al valor por defecto que es alpha = 1\n",
    "ridge.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594473740444",
   "display_name": "Python 3.7.7 64-bit ('test': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}