{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595776707318",
   "display_name": "Python 3.7.7 64-bit ('test': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria tensor flowe\n",
    "import tensorflow as tf\n",
    "# Daset de datos con números escritos a manorom \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow_datasets as tfds\n",
    "# API de tensorfow para construir y entrenar modelos de alto nivel\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una set de datos que es un array de seis elementos\n",
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los dataset se pueden procesar en lotes, batch.\n",
    "# En la siguiente convertimos nuestro dataset en batch\n",
    "# indicando que lotes sean de 3 en 3\n",
    "dataset_batch = dataset.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[8, 3, 0]\n[8, 2, 1]\n[20]\n"
    }
   ],
   "source": [
    "# Se recorre los set de datos. El take indica cuantos\n",
    "# veces se van a leer datos\n",
    "for batch in dataset_batch.take(100):\n",
    "  print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Número de datos que se leen en cada pasada: [3, 3, 1]\nNúmero valores a pasar a taken:  3\n"
    }
   ],
   "source": [
    "# Vamos a ver cuantos pasadas hay que hacer para leer los datos\n",
    "# Genera un array con los valores que se leen cada pasada.\n",
    "batch_sizes = [batch.shape[0] for batch in dataset_batch]\n",
    "batch_taken = len([batch.shape[0] for batch in dataset_batch])\n",
    "print(\"Número de datos que se leen en cada pasada:\", batch_sizes)\n",
    "print(\"Número valores a pasar a taken: \", batch_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Inicio época:  0\n[8, 3, 0]\n[8, 2, 1]\n[20]\nFin epoca:  0\nInicio época:  1\n[8, 3, 0]\n[8, 2, 1]\n[20]\nFin epoca:  1\nInicio época:  2\n[8, 3, 0]\n[8, 2, 1]\n[20]\nFin epoca:  2\n"
    }
   ],
   "source": [
    "# En algoritmos de entrenamiento lo que se hacen son pasadas \n",
    "# para mejorar la calidad del aprendizaje. \n",
    "# En este ejemplo se procesa 3 veces los datos del\n",
    "# dataset\n",
    "for epoch in range(3):\n",
    "    print(\"Inicio época: \", epoch)\n",
    "    for batch in dataset_batch.take(100):\n",
    "        print([arr.numpy() for arr in batch])\n",
    "    print(\"Fin epoca: \", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}